from statsmodels.stats.outliers_influence import summary_table
st, data, ss2 = summary_table(lr, alpha=0.05)

fittedvalues = data[:,2]
predict_mean_se  = data[:,3]
# predict_mean_ci_low, predict_mean_ci_upp = data[:,4:6].T # do we need it ?
predict_ci_low, predict_ci_upp = data[:,6:8].T
print(predict_ci_low)

# confs = t * np.sqrt((s_err / (n - 2)) * (1.0 / n + (np.power((p_x - mean_x), 2) /
#                                                     ((np.sum(np.power(x, 2))) - n * (np.power(mean_x, 2))))))

xrng = range(len(fittedvalues))
plt.plot(xrng, y_trn, 'o')
plt.plot(xrng, fittedvalues, '-', lw=2)
plt.plot(xrng, predict_ci_low, 'r--', lw=2)
plt.plot(xrng, predict_ci_upp, 'r--', lw=2)
# plt.plot(x, predict_mean_ci_low, 'r--', lw=2)
# plt.plot(x, predict_mean_ci_upp, 'r--', lw=2)
plt.show()





# TODO rewrite
from sklearn.model_selection import  GridSearchCV
# cv_params = {
#     'max_depth':[3,5,7],
#     'min_child_weight':[1,3,5]
# }
#

# ind_params = {
#     'objective': 'reg:linear',
#     'booster': 'gblinear',
#     'learning_rate':0.1,
#     'n_estimators': 1000,
#     'seed':0,
#     'subsample': 0.8,
#     'colsample_bytree': 0.8,
# }
# opt_gbm = GridSearchCV( xgb.XGBClassifier(ind_params),
#                         cv_params,
#                         scoring='accuracy',
#                         cv=5,
#                         n_jobs=-1)
#
# opt_gbm.fit(x_trn, y_trn)
# print(opt_gbm.cv_results_)


params = {
    'objective': 'reg:linear',
    'booster': 'gblinear'
}
trees = 1000

crossval = xgb.cv(params, dtrain, metrics=('rmse'), verbose_eval=False, nfold=10, show_stdv=False, num_boost_round=trees)
bst = xgb.train(params, dtrain, num_boost_round=crossval['test-rmse-mean'].argmin())
# cv.plot(y=['test-rmse-mean', 'train-rmse-mean'])
# plt.show()
dev = min(crossval['test-rmse-mean'])

# plot vs y_trn
# pred_trn = bst.predict(dtrain)

# confidence=1.96
pred_tst = bst.predict(dtest)
# lower = pred_tst - confidence*dev
# upper = pred_tst + confidence*dev

# anomalies = np.array([np.NaN]*len(y_tst))
# anomalies[y_tst<lower] =  y_tst[y_tst<lower]
# bst_reg_df = pd.DataFrame(data=np.array([pred_tst, upper, lower]).T, columns=['predicted', 'upper','lower'])

print(mean_absolute_error(pred_tst,y_tst))

[  3.72182608e+03   5.88566318e+03   1.75000000e-01   9.00000000e+02]